# -*- coding: utf-8 -*-
"""Final Project Movie Recommen dationSystem .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_fVzKASNGP1gObppYLhcKTpTQZympWcd

# Import Libraries
"""

import numpy as np
import pandas as pd
import os
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.feature_extraction.text import TfidfVectorizer
from google.colab import drive
import matplotlib.pyplot as plt
drive.mount('/content/drive')

"""# Load and Preprocess Data"""

# loading dataset
movie_dataset = pd.read_csv("/content/drive/MyDrive/netflix-rotten-tomatoes-metacritic-imdb.csv (1).zip")

# shape for netflix dataset
movie_dataset.shape

movie_dataset.head(15)

movie_dataset.info()

movie_dataset.dtypes

# describe
movie_dataset.describe()

# checking number of columns and their datatype
movie_dataset.info()

"""# Data Cleaning and Imputation"""

# remove duplicate data
movie_dataset.drop_duplicates(inplace = True)

# drop columns with 30% or more missing data
missing_data = (movie_dataset.isnull().sum() / len(movie_dataset)) * 100
columns_missing_data = missing_data[missing_data >= 30].index
movie_dataset.drop(columns = columns_missing_data, inplace = True)

movie_dataset.info()

# grouped all columns with non-numeric values and are objects
object_columns = movie_dataset.select_dtypes(exclude = ['int', 'float']).columns
object_columns = movie_dataset[object_columns]
object_columns.info()

from sklearn.impute import SimpleImputer

# Initialize the imputer
imp = SimpleImputer(strategy='most_frequent')

# List of columns to impute
columns_to_impute = ['Tags', 'Genre', 'Languages', 'Runtime', 'Writer', 'Actors', 'Release Date']

# Impute the non-numeric values using most_frequent strategy
for column in columns_to_impute:
    if object_columns[column].dtype == 'object':  # Check if the column is categorical
        object_columns[column] = imp.fit_transform(object_columns[[column]]).ravel()
    elif object_columns[column].dtype in ['int64', 'float64']:  # Check if the column is numeric
        object_columns[column] = imp.fit_transform(object_columns[[column]]).ravel()

object_columns.info()

# Store all columns that have int or float as their datatypes
numeric_columns = movie_dataset.select_dtypes(include = ['int', 'float']).columns
numeric_columns= movie_dataset[numeric_columns]

numeric_columns.info()

# Impute these features using the mean method
imp = SimpleImputer(strategy = 'mean')
numeric_columns['IMDb Score'] = imp.fit_transform(numeric_columns[['IMDb Score']])
numeric_columns['IMDb Votes'] = imp.fit_transform(numeric_columns[['IMDb Votes']])
numeric_columns['Hidden Gem Score'] = imp.fit_transform(numeric_columns[['Hidden Gem Score']])
numeric_columns.info()

# merge numerical and non-numerical features
Merged_data = pd.DataFrame()
Merged_data = pd.concat([object_columns, numeric_columns], axis = 1)
Merged_data.info()

# Handle missing values
Merged_data.dropna(how='any', inplace = True)
Merged_data.info()

# Saving cleaned dataset
Merged_data.to_csv('Movie_data.csv', index = False)

# Extract the primary genre for the genre column
Merged_data['Genre'] = Merged_data['Genre'].str.replace(r'[', '').str.replace(r"'", '').str.replace(r']', '').str.split(',').str[0]

"""# Exploratory Data Analysis"""

# Description
Merged_data.describe()

# Histograms
Merged_data.hist(figsize=(12,10))
plt.tight_layout()
plt.show()

# Distribution of Genre
genre_count=Merged_data['Genre'].value_counts()
plt.figure(figsize=(12,6))
genre_count.plot(kind='bar')
plt.title('Genre Distribution of Movies')
plt.xlabel('genre')
plt.ylabel('Count')
plt.show()

"""##### The bar chart above shows which genres are most common in the dataset. Comedy is the most popular genre, followed by drama and action. Genres like talk-shows, war, adult, reality, western, and sports are less popular."""

import plotly.graph_objects as go

# Analyze comparison between Movie and Series in the Dataset
count = Merged_data['Series or Movie'].value_counts()

fig = go.Figure(data=[go.Bar(
    x=Merged_data["Series or Movie"],
    y=count,
    text=count,
    textposition='auto',

)])
fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')
fig.update_layout(
    title_text='Comparison between Movie and Series in the dataset',
    uniformtext_minsize=8, uniformtext_mode='hide',
    barmode='group', xaxis_tickangle=-45,
    yaxis=dict(title='Quantity', titlefont_size=14),
    xaxis=dict(title='Category', titlefont_size=14)
)

# Show the plot
fig.show()

# Create boxplot to analyze our genres
plt.figure(figsize=(16,8))
sns.boxplot(x='Genre', y='IMDb Score',data=Merged_data)
plt.title('Ratings by Genre')
plt.xlabel('Genre')
plt.ylabel('Rating')
plt.xticks(rotation=45,ha='right')
plt.show()

Merged_data.dtypes

import matplotlib.pyplot as plt
import seaborn as sns

# Compute correlation matrix for numeric columns
correlation_mat = numeric_columns.corr()

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_mat, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

"""#### The above correlation map is what we are using to understand the relationship between the different variables in the dataset, movies_dataset. The diagonal line, red indicates a perfect correlation between the variable and itself.

"""

# Analyse Movie rating over the years using graph
plt.figure(figsize=(12, 6))
Merged_data['Release Date'] = pd.to_datetime(Merged_data['Release Date'])
Merged_data.groupby(Merged_data['Release Date'].dt.year)['IMDb Votes'].mean().plot()
plt.title('Average Rating Over Years')
plt.xlabel('Year')
plt.ylabel('Average Rating')
plt.show()

"""#### The above graph shows that the average IMDB ratings has changed a lot over the years. The 1920s to the 1940s have many ups and downs with a big peak in 1940's, followed by a drop. From the 1960s to the 2000s, there are more high points, especially in the late 1960s and 1980s. However, from 2000 to 2020, the average votes decrease, showing less audience engagement in recent years.

"""

# Pairplot for numerical features
sns.pairplot(Merged_data, diag_kind='kde')
plt.show()

"""#### The pairplot shows that the movies labeled as 'hidden gems' tend to have higher IMDb scores, suggesting that they are well-regarded despite being less known. However, the number of IMDb votes does not affect this rating or the hidden gem status. The right-skewed distributions show that while most movies receive average ratings and votes, a few stand out with high ratings or vote counts."""

pip install wordcloud

""" Our system uses word clouds to highlight common themes in movie descriptions which helps us
refine content-based recommendations by focusing on frequently occurring words. """

from wordcloud import WordCloud

wordcloud=WordCloud(width=800,height=400,background_color='white').generate(' '.join(Merged_data['Summary'].dropna()))
plt.figure(figsize=(12,6))
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud For Movie Descriptions')
plt.show()

"""#### In word clouds, word size represents frequency. Larger words like 'find,' 'life,' and 'family' are more common in our movie descriptions, while smaller words appear less frequently.

# Feature Engineering

#### Building the Movie Recommender System
"""

# Import the NLTK library
import nltk
nltk.download('stopwords') # Download stopwords

from nltk.stem.porter import PorterStemmer

# Initialize Porter Stemmer to normalize words and reduce variations
ps = PorterStemmer()

# Apply steming on selected column and return the processed text as a single string
def xStem(text):
    stemmed_words = []
    for word in text.split():
        stemmed_words.append(ps.stem(word))
    return " ".join(stemmed_words)

# Stem the text in the 'Summary' column and update the Summary column with the stemmed text
Merged_data['Summary'] = Merged_data['Summary'].apply(xStem)

# Display the first entry in the updated 'Summary' column
Merged_data['Summary'][0]

"""# Vectorization"""

# Create a TfidfVectorizer with english words removed and we will fit and transform our movie descriptions into Tf-idf vectors
vectorizer = TfidfVectorizer(stop_words = 'english')
vectorized_Merged_data = vectorizer.fit_transform(Merged_data['Summary'])

vectorizer

vectorized_Merged_data

# Convert movie summary into numerical vectors using TfidVectorizer
movie_summary_vectors = vectorizer.fit_transform(Merged_data['Summary']).toarray()
movie_summary_vectors

"""## Calculate Vectors Similarities & Distances"""

# Display the numerical vector representation of the first movie's Summary
movie_summary_vectors[0]

# Import cosine_similarity to Calulate Distance between the Vectors
from sklearn.metrics.pairwise import cosine_similarity

# Calculate the similarity between the Tf-idf vectors in our vectorized movie dataset.
movie_similarity = cosine_similarity(vectorized_Merged_data, vectorized_Merged_data)

# Shape
movie_similarity.shape

movie_similarity

movie_similarity[0]

""" Display the similarity scores of the first movie with all other movies.
    Similarity with itself is at index 0. """

print("Shape of Similarity Scores for First Movie: ", movie_similarity[0].shape)
print("\n", "-"*35, "\n Similarity Scores for the First Movie ","\n","-"*35, "\n", movie_similarity[0])

""" Convert similarity scores into a list of tuples created that help in sorting,
 and retrieve the top 5 most similar movies """

top_similar_movies = sorted(list(enumerate(movie_similarity[0])), reverse=True, key=lambda x:x[1])[1:6]

top_similar_movies

"""# Recommendations

#### Our resulting movies_similarity will be used in our content-based recommendation system. This similarity matrix will be used to identify and recommend movies that are similar to a given movie.
"""

""" Create a variable movie_indices to store a panda series.
    This will help to map movie titles to their indices later on in our code. """

movie_indices = pd.Series(Merged_data.index, index = Merged_data['Title'])

"""# Training and Evaluating the Model"""

# Function that takes a movie title and returns the index of the specified movie.
def get_movie_title_index(movie, indices):
  index = indices[movie]
  if isinstance(index, np.int64):
    return index
  else:
    t = 0
    print('Select title: ')
    for i in range(len(index)):
      print(f'({i} - {Merged_data["Title"].iloc[index[i]]})', end=' ')
    rt = int(input())
    return index[t]

# Retrieve the index of the movie title 'The Avengers' from the movie_indices dictionary
get_movie_title_index('The Avengers', movie_indices)

# Function to recommend similar movies to the users based on the titles inputed
def recommend_movie_titles(movie_title, indices, cosine_similarity):
    print(f"\nMovie selected: {movie_title}")
    title_index = get_movie_title_index(movie_title, indices)
    if title_index is None:
        return

    print(f"\nRecommended Movies for ({movie_title}):")

    index = indices[movie_title]
    similarity = sorted(list(enumerate(cosine_similarity[index])), key=lambda x: x[1], reverse=True)
    similarity_list = similarity[1:6]

    for i in similarity_list:
        recommended_title = Merged_data['Title'].iloc[i[0]]
        recommended_year = Merged_data['Release Date'].iloc[i[0]]
        recommended_genre = Merged_data['Genre'].iloc[i[0]]
        print(f"Title: {recommended_title} | Date: {recommended_year} | Genre: {recommended_genre}")

"""# Model Evaluation and Optimization

### As this is a content-based recommender system, we have primarily used cosine similarity for evaluating the model. However, we tested with different movie titles to check the effectiveness of recommendations.
"""

# Get movie recommendations based on similarity for each specified movie
recommend_movie_titles('The Avengers', movie_indices, cosine_similarity=movie_similarity)
recommend_movie_titles('The Butterflys Dream', movie_indices, cosine_similarity = movie_similarity)
recommend_movie_titles('I Am Mother', movie_indices, cosine_similarity=movie_similarity)
recommend_movie_titles('Hedgehogs', movie_indices, cosine_similarity=movie_similarity)
recommend_movie_titles('2067', movie_indices, cosine_similarity = movie_similarity)
recommend_movie_titles('Lets Fight Ghost', movie_indices, cosine_similarity=movie_similarity)

"""# Recommend Movie Names with Poster"""

import pandas as pd
from IPython.display import display, HTML

# Fetch the poster URL for a recommended movie from the local dataset
def get_poster_url(poster_path):
    if poster_path:
        return poster_path
    else:
        return "https://via.placeholder.com/575x300?text=No+Poster+Available"

# Function to recommend movies and fetch their posters based on a given movie
def recommend_movies_and_posters(input_movie_title):
    try:
        # Find the index of the input movie
        movie_index = Merged_data[Merged_data["Title"].str.lower() == input_movie_title.lower()].index[0]
        similarity_scores = movie_similarity[movie_index]
        list_of_movies = sorted(list(enumerate(similarity_scores)), reverse=True, key=lambda x: x[1])[1:7]

        recommended_movies = []
        poster_urls = []
        for index in list_of_movies:
            movie = Merged_data.iloc[index[0]]
            recommended_movies.append(movie["Title"])
            # Fetch the poster URL from the 'Poster' column
            poster_urls.append(get_poster_url(movie["Poster"]))

        return recommended_movies, poster_urls
    except Exception as e:
        print(f"Error in recommending movies: {e}")
        return [], []

# Function to display recommended movie names and their posters
def display_movie_recommendations(selected_movie, movie_titles, poster_urls):
    display(HTML(f"""
    <div style="font-size:24px; font-weight:Bold; color:#fff; text-align:center; padding-top:8px; height:12%; width: 100%; border:1px solid #ccc; border-radius:10px; margin-top:10px; background-color:green;">
        Recommendations for: {selected_movie}
    </div>
    <table>
        <tr>
            {"".join([f'<td><img src="{url}" style="border-radius:10px; width:575px; height:300px;"></td>' for url in poster_urls])}
        </tr>
        <tr>
            {"".join([f'<td><p style="text-align:center; font-size:14px; font-weight:bold">{title}</p></td>' for title in movie_titles])}
        </tr>
    </table>"""))

# Test our Recommendation system with 6 movies from our dataset
movies_to_recommend = ["The Avengers","The Butterflys Dream","I Am Mother", "Hedgehogs", "2067","Lets Fight Ghost"]
for movie in movies_to_recommend:
    recommended_titles, poster_urls = recommend_movies_and_posters(movie)
    display_movie_recommendations(movie, recommended_titles, poster_urls)

"""# Saving the Recommendation Model for Deployment"""

import joblib

# Save the model Components using Joblib
model_components={
    'tfidf_vectorizer':vectorizer,
    'cosine_similarity_matrix': movie_similarity,
    'indices_mapping':movie_indices
}

# Save the model using Joblib
joblib.dump(model_components, 'content_based_recommender.pkl')
joblib.dump(Merged_data, 'Merged_data.pkl')

"""# Load the Model"""

# Load the model components
loaded_components = joblib.load('content_based_recommender.pkl')
loaded_vectorizer = loaded_components['tfidf_vectorizer']
loaded_cosine_sim = loaded_components['cosine_similarity_matrix']
loaded_indices = loaded_components['indices_mapping']

# Load the merged data
loaded_Merged_data = joblib.load('Merged_data.pkl')

# Use the loaded model for recommendations
def recommend_movies_loaded_model(title, loaded_cosine_sim=loaded_cosine_sim, loaded_indices=loaded_indices, Merged_data=loaded_Merged_data):
    idx = loaded_indices.get(title)
    if idx is None:
        print(f"Title '{title}' not found in the dataset.")
        return []

    sim_scores = list(enumerate(loaded_cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return Merged_data[['Title', 'Release Date', 'Genre']].iloc[movie_indices]

# Test the loaded model
recommended_movies_loaded = recommend_movies_loaded_model('Lets Fight Ghost')
print(recommended_movies_loaded)